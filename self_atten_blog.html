<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Programming - Self Attention in Textual Clustering</title>
<script>if(localStorage.getItem('theme')==='dark'){document.documentElement.classList.add('dark-mode');}</script>
<link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&display=swap" rel="stylesheet">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.5/theme/material-darker.min.css">
<style>
:root {
  --text-color: #333;
  --bg-color: #f5f5f5;
  --card-bg: #ffffff;
  --timeline-bg: #e9ecef;
  --border-color: #dee2e6;
  --shadow-color: rgba(0,0,0,0.1);
  --blockquote-color: #6c757d;
}
html.dark-mode {
  --text-color: #dcdcdc;
  --bg-color: #2e2e2e;
  --card-bg: #3a3a3a;
  --timeline-bg: #444;
  --border-color: #555;
  --shadow-color: rgba(0,0,0,0.25);
  --blockquote-color: #aaa;
}
body {
  font-family: 'Roboto', sans-serif;
  background-color: var(--bg-color);
  color: var(--text-color);
  font-size: 18px;
  line-height: 1.6;
  transition: background-color 0.3s, color 0.3s;
}
.navbar {
  background-color: #6c757d;
  box-shadow: 0 2px 5px var(--shadow-color);
}
.navbar.dark-mode {
  background-color: #343a40;
}
.card {
  background-color: var(--card-bg);
  box-shadow: 0 2px 4px var(--shadow-color);
  border: none;
  transition: background-color 0.3s, box-shadow 0.3s;
}
.card:hover {
  box-shadow: 0 4px 8px var(--shadow-color);
}
.timeline {
  position: relative;
  max-width: 800px;
  margin: 40px auto;
  padding: 20px 0;
}
.timeline::before {
  content: "";
  position: absolute;
  top: 0;
  bottom: 0;
  left: 50%;
  width: 4px;
  background: #6c757d;
  transform: translateX(-50%);
}
.timeline-item {
  position: relative;
  width: 50%;
  padding: 20px;
  box-sizing: border-box;
  margin-bottom: 30px;
}
.timeline-item.left {
  left: 0;
  text-align: right;
}
.timeline-item.right {
  left: 50%;
  text-align: left;
}
.timeline-content {
  padding: 15px;
  background: var(--timeline-bg);
  border-radius: 6px;
  box-shadow: 0 2px 4px var(--shadow-color);
  position: relative;
  transition: background-color 0.3s;
}
.timeline-item.left .timeline-content::after {
  content: "";
  position: absolute;
  top: 50%;
  right: -20px;
  width: 20px;
  height: 2px;
  background: #6c757d;
}
.timeline-item.right .timeline-content::after {
  content: "";
  position: absolute;
  top: 50%;
  left: -20px;
  width: 20px;
  height: 2px;
  background: #6c757d;
}
.timeline-date {
  font-weight: bold;
  margin-bottom: 6px;
}
.scroll-animate {
  opacity: 0;
  transform: translateY(20px);
  transition: opacity 0.6s ease-out, transform 0.6s ease-out;
}
.animate__fadeInUp {
  opacity: 1 !important;
  transform: translateY(0) !important;
}
.theme-blockquote {
  border-left: 4px solid var(--blockquote-color);
  padding-left: 1rem;
  color: var(--blockquote-color);
  transition: border-left-color 0.3s, color 0.3s;
}
figure {
  display: block;
  clear: both;
  margin: 10px 0;
  transition: box-shadow 0.3s;
}
figcaption {
  margin-top: 4px;
  font-size: 0.85em;
  font-style: italic;
  text-align: center;
  color: var(--text-color);
  opacity: 0.8;
  transition: color 0.3s;
}
pre {
  background-color: var(--card-bg);
  border-radius: 4px;
  padding: 15px;
  box-shadow: 0 2px 4px var(--shadow-color);
  transition: background-color 0.3s;
}
.btn {
  transition: transform 0.2s, box-shadow 0.2s;
}
.btn:hover {
  transform: translateY(-2px);
  box-shadow: 0 4px 8px var(--shadow-color);
}
@media (max-width: 768px) {
  .timeline::before {
    left: 10px;
  }
  .timeline-item {
    width: 100%;
    text-align: left;
  }
  .timeline-item.left, .timeline-item.right {
    left: 0;
  }
  .timeline-item.left .timeline-content::after,
  .timeline-item.right .timeline-content::after {
    left: -20px;
    right: auto;
  }
}
.CodeMirror {
  height: 100%;
  font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
  font-size: 14px;
}
html.dark-mode .CodeMirror {
  border-color: var(--border-color);
}
html.dark-mode .btn-light {
  background-color: #555;
  color: #dcdcdc;
  border-color: #666;
}
html.dark-mode .alert {
  color: #f8f9fa;
}
html.dark-mode .alert-info {
  background-color: #17a2b8;
}
html.dark-mode .alert-danger {
  background-color: #dc3545;
}
html.dark-mode .jumbotron {
  background-color: #343a40;
}
body { padding-bottom: 50px; }
</style>
</head>
<body>
<a id="top"></a>
<nav class="navbar navbar-expand-lg navbar-dark">
  <div class="container">
    <a class="navbar-brand" href="index.html">Harry's Blog</a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li><li class="nav-item"><a class="nav-link" href="blog.html">Blog</a></li><li class="nav-item"><a class="nav-link" href="projects.html">Projects</a></li><li class="nav-item"><a class="nav-link" href="about.html">About Me</a></li>
        <li class="nav-item">
          <button id="toggleTheme" class="btn btn-outline-light">ðŸŒ“</button>
        </li>
      </ul>
    </div>
  </div>
</nav>
<div class="container mt-5">
<h1 style='text-align: left;'>Programming - Self Attention in Textual Clustering</h1>
<p style='text-align: left;'><small>2025-03-08</small></p>
<p style='text-align: left;'><small>By Harry Yin</small></p>
<p style='text-align: left;'><small>Estimated read time: 2 minutes</small></p>
<hr>
<p>A while back, while working on Alitheia AI, I had the idea to apply self-attention to textual clustering after learning about what self-attention was. Unfortunately, I didn't know how to train the self-attention model then, so I left it untrained.</p>
<p>Surprisingly, however, the self-attention often somewhat improved the textual clarity of the clustering while also massively improving the cluster's scoring on a series of metrics. </p>
<p>Thus, in this blog, I wanted to explore some possibilities as to why this may have occurred.</p>
<p>First and foremost, it turned out that my idea was not as novel as I thought it was as. There is an excellent paper about this topic that I will be using as reference for the rest of the blog: Lovedeep Singh's <a href="https://arxiv.org/pdf/2201.02816">Clustering Text Using Attention</a>.</p>
<p>Taking a look at Singh's results the average improvement of about 174.65% from baseline clustering to clustering after applying AP2 (attention clustering w/pre-trained embeddings and using 20% of data for training), which is certainly impressive. Furthermore, applying AP9 saw even more improvement, although variable.</p>
<p>However, the issue lies with the fact that when doing my own tests with an untrained self-attention model, I saw a consistent improvement of about 161.22%, which isn't too far off from Singh's result with trained models. </p>
<p>That was surprising since theoretically, the untrained model should have seen, on average, no improvement in clustering, yet it showed consistent improvements. This got me thinking that maybe given how silhouette scores were calculated, any sort of self-attention, if consistent, could improve clustering.</p>
<p>The idea behind this depends on the fact that silhouette scores are calculated purely on a numerical basis and determined through relative similarity between clusters. Self-attention, meanwhile applies both amplifying and dampening weights, meaning that if applied consistently, certain similar sets of values will be decreased or increased. My belief is that given such effects, a sort of artificial dimensional reduction is applied. Due to some values being dampened into irrelevance, an effect similar to that of UMAP of PCA reduction might have occurred, resulting in greater cluster separability due to the algorithm having less nuance to worry about.</p>
<p>The issue with this is that such clustering doesn't actually guarantee better clustering since random words or phrases will be amplified. Thus, I can only chalk up the improved perceived clustering to luck, but I still need to do more tests on the perceived clustering improvements to be sure. Furthermore, I think it is necessary to find a better and more universal scoring metric for textual clustering in particular, as, otherwise, there won't be a consistent method to determine the validity of textual clusters.</p>
<p>All in all, the conclusion I came to was that self-attention is indeed a useful tool for improving textual clustering and that using silhouette scores as a scoring metric is not such a good idea. Overall, this was a very interesting topic to look into, and I think it is an area that needs a lot more research. </p>
<p>Cheers!</p>
<div style="text-align:center; margin:20px;"><a href="#top" class="btn btn-secondary">Back to top</a></div>
</div>
<footer class="footer mt-5 py-3 bg-light text-center">
  <div class="container">
    <span class="text-muted">&copy; 2025 Harry Yin. All rights reserved.</span>
  </div>
</footer>
<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
  const observer = new IntersectionObserver((entries) => {
    entries.forEach(entry => {
      if (entry.isIntersecting) {
        entry.target.classList.add('animate__animated', 'animate__fadeInUp');
        observer.unobserve(entry.target);
      }
    });
  }, { threshold: 0.3, rootMargin: '0px 0px -50px 0px' });
  
  document.querySelectorAll('.scroll-animate').forEach(el => observer.observe(el));

  const themeToggle = document.getElementById("toggleTheme");
  themeToggle.addEventListener("click", function() {
    document.documentElement.classList.toggle("dark-mode");
    localStorage.setItem('theme', document.documentElement.classList.contains("dark-mode") ? 'dark' : 'light');
    
    // Update footer class based on theme
    const footer = document.querySelector('footer');
    if (document.documentElement.classList.contains("dark-mode")) {
      footer.classList.replace('bg-light', 'bg-dark');
    } else {
      footer.classList.replace('bg-dark', 'bg-light');
    }
  });
  
  // Setup correct footer class on load
  if (document.documentElement.classList.contains('dark-mode')) {
    document.querySelector('footer').classList.replace('bg-light', 'bg-dark');
  }

  document.querySelectorAll('a[href="#top"]').forEach(function(link) {
    link.addEventListener("click", function(e) {
      e.preventDefault();
      window.scrollTo({top: 0, behavior: "smooth"});
    });
  });

  document.querySelectorAll('[data-toggle="tooltip"]').forEach(el => {
    new bootstrap.Tooltip(el);
  });

  console.log('Custom JS loaded');
});
</script>
</body>
</html>
