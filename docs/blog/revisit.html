<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <title>Programming - Revisiting old projects | Harry Yin&#39;s Portfolio</title>
    <meta name="description" content="A showcase of my projects and thoughts :D">
    <meta name="keywords" content="portfolio, projects, blog, developer">
    <meta name="author" content="Harry Yin">

    <meta property="og:type" content="website">
    <meta property="og:url" content="https://xild076.github.io/blog/revisit.html">
    <meta property="og:title" content="Programming - Revisiting old projects | Harry Yin&#39;s Portfolio">
    <meta property="og:description" content="A showcase of my projects and thoughts :D">
    <meta property="og:image" content="">
    <meta property="og:site_name" content="Harry Yin&#39;s Portfolio">

    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://xild076.github.io/blog/revisit.html">
    <meta property="twitter:title" content="Programming - Revisiting old projects | Harry Yin&#39;s Portfolio">
    <meta property="twitter:description" content="A showcase of my projects and thoughts :D">
    <meta property="twitter:image" content="">

    <link rel="icon" href="/static/img/favicon.svg" type="image/svg+xml">
    <link rel="stylesheet" href="/static/css/style.css">

    <script>
      (function() {
        const theme = localStorage.getItem('theme') || (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light');
        document.documentElement.setAttribute('data-theme', theme);
      })();
    </script>
</head>
<body>
    <a href="#main-content" class="skip-link">Skip to main content</a>

        <header class="site-header">
  <div class="container d-flex justify-content-between align-items-center">
    <div class="site-title"><a href="/index.html">Harry Yin&#x27;s Portfolio</a></div>
    <nav class="justify-content-center nav-main"  style="margin-top: 0; margin-bottom: 0"><ul class="nav"><li class="nav-item"><a class="nav-link " href="/index.html">Home</a></li><li class="nav-item"><a class="nav-link " href="/projects.html">Projects</a></li><li class="nav-item"><a class="nav-link " href="/blog.html">Blog</a></li><li class="nav-item"><a class="nav-link " href="/cool_stuff.html">Cool Stuff</a></li><li class="nav-item"><a class="nav-link " href="/about.html">About</a></li></ul></nav>
    <button id="theme-toggle" title="Toggle theme" class="">ðŸŒ“</button>
  </div>
</header>

    <main id="main-content" role="main">
<div class="container py-lg"  style="margin-bottom: var(--spacing-md)"><p class="h1 mb-lg text-center text-left"  style="margin-bottom: var(--spacing-md); font-size: 3.5rem" data-scroll-animation="fade-in-down">Programming - Revisiting old projects</p><div class="align-items-start blog-post-meta d-flex flex-row flex-wrap justify-content-center mb-md text-muted"  style="margin-top: var(--spacing-sm); margin-bottom: 0"><p class="meta-item text-left"  style="margin-top: 0; margin-bottom: 0; color: var(--bs-gray-600)">By Harry Yin</p><p class="meta-separator mx-sm text-left"  style="margin-top: 0; margin-bottom: 0; color: var(--bs-gray-600)">â€¢</p><p class="meta-item text-left"  style="margin-top: 0; margin-bottom: 0; color: var(--bs-gray-600)">Published on 2025-07-25</p><p class="meta-separator mx-sm text-left"  style="margin-top: 0; margin-bottom: 0; color: var(--bs-gray-600)">â€¢</p><p class="meta-item text-left"  style="margin-top: 0; margin-bottom: 0; color: var(--bs-gray-600)">2 min read</p></div><hr class="divider" style="margin-top: var(--spacing-lg); margin-bottom: var(--spacing-lg); border: 0; border-top-width: 1px; border-top-style: solid; border-top-color: var(--bs-border-color); height: 0; opacity: 0.25"><div class="markdown-content"  style="margin-bottom: var(--spacing-md)"><p>About two weeks ago, I decided to revisit a few of my older projects / projects I put on hold, those being PolyStock AI and Alitheia AI, and oh boy have things changed. It's really surprising, coming back to projects and realizing there is so much things you can do that you've never thought up of seen before. I remember reading a while back about cognitive expertise in <a rel="nofollow noopener" target="_blank" href="https://journals.aom.org/doi/full/10.5465/amr.35.4.zok579"><em>Reconsidering the Trade-off Between Expertise and Flexibility: a Cognitive Entrenchment Perspective</em> by Erik Dane</a>, and if I do say so myself, I believe that I'm just on the cusp of falling into entrenchment, so I still have some wiggle room to squeeze out new ideas. </p>

<p>Boring things aside, let's get into the fun things: what exactly changed? Since going into detail will take way too long to write, I'll focus on one big thing for every project.</p>

<p>For PolyStock AI, the big change I made was in terms of model architecture. A few months prior, I was watching a youtube series on how ChatGPT worked, and I noticed that the sequence to sequence system could be used to predict extended stock prices pretty well. As seq2seq puts words after words, I thought that it would be applicable to put it with stock prices, where instead of words, it would be price point after price point. Using seq2seq for time-series modeling definitely isn't a new thing, see <a rel="nofollow noopener" target="_blank" href="https://arxiv.org/abs/1805.03714"><em>Foundations of Sequence-to-Sequence Modeling for Time Series</em> by Kuznetsov et al</a>, however, I've never seen it applied to stock data in specific, so I tried implementing it. </p>

<p>It turned out much better than I would have though, see the StockPred project, and it really surprised me. Seq2seq and transformers as a whole are, first and foremost, a probability thing, so seeing it work for continuous values was unusual, however, there has been research done on using it for continuous values, so I guess it isn't too out there, see <a rel="nofollow noopener" target="_blank" href="https://arxiv.org/html/2501.18793v1"><em>OT-Transformer: A Continuous-time Transformer Architecture with Optimal Transport Regularization</em> by Kan et al</a>. </p>

<p>For Alitheia AI, the big change I made was in terms of how I optimized by clustering systems. This has always been a major problem for meâ€”finding the optimal clustering systems is very difficult, especially since you can't exactly "train" them in the conventional sense. However, while I was messing around with another random project of mine, not something that I actually wanted to put on my transcripts or anything, I found out about Optuna, a hyperparameter optimization method. A few months after that, it came to me that I could use Optuna to optimize the hyperparameters of my clustering system while using custom-generated ground truth clustering datasets.</p>

<p>It worked... well? While it wasn't perfect, 9 times out of 10, it would provide better clustering than arbitrary values, but there is always still that 10%. Clustering is just so unlike conventional ML systems, which makes it just as difficult to mess around with. </p>

<p>For both of these concepts however, I definitely think there is a lot more that needs to be looked at. For the clustering, task-specific hyperparameter optimization could be very useful, but I don't see too much potential as it's a pretty niche task. Transformer-based continuous time-series predictions are definitely worth looking into though as they could come in handy for a lot of things, and for both of these concepts, I would love to hear any insights people have on them.</p>

<p>Cheers!</p>
</div></div>    </main>

    <footer class="site-footer">
        <div class="container">
            &copy; 2025 Harry Yin. All rights reserved.
            <p class="text-muted mt-xs">Powered by Custom developed SiteGen(.py)</p>
        </div>
    </footer>

    <script src="/static/js/main.js"></script>
</body>
</html>